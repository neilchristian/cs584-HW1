{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/neil/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Import the pandas package, then use the \"read_csv\" function to read\n",
    "# the labeled training data\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import os\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy.linalg as LA\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "\n",
    "\n",
    "def most_common(list):\n",
    "    data = Counter(list)\n",
    "    if data.most_common(1)[0][0] ==1:\n",
    "        return \"+1\"\n",
    "    else: \n",
    "        return \"-1\"\n",
    "def majority_vote(indicies, sentiment):\n",
    "    sentimentlist = []\n",
    "    for index in indicies:\n",
    "        sentimentlist.append(sentiment[index])\n",
    "    return most_common(sentimentlist)\n",
    "\n",
    "def getNeighbors(testinstance, train_set, k):\n",
    "    cosine_similarities = cosine_similarity(testinstance, train_set).flatten()\n",
    "    related_docs_indices = cosine_similarities.argsort()[:-(k+2):-1]\n",
    "    x =cosine_similarities[related_docs_indices]\n",
    "    x = list(x)\n",
    "    neighbors = x[1:]\n",
    "    return neighbors\n",
    "\n",
    "def getResponse(testinstance, train_set, k):\n",
    "    cosine_similarities = cosine_similarity(testinstance, train_set).flatten()\n",
    "    related_docs_indices = cosine_similarities.argsort()[:-(k+2):-1]\n",
    "    related_docs_indices = related_docs_indices[1:]\n",
    "    return related_docs_indices\n",
    "\n",
    "#import train data into pandas\n",
    "train = pd.read_csv(\"train.data\", header = None, names = ['sentiment', 'review'],delimiter=\"\\t\")\n",
    "\n",
    "#import test data into pandas dataframe\n",
    "import os\n",
    "file = open(os.path.join( os.path.dirname('_file_'), 'test.data'), 'r')\n",
    "test1 = file.readlines()\n",
    "test1 =list(test1)\n",
    "test = pd.DataFrame(test1)\n",
    "\n",
    "#test = pd.read_csv('test.data', header = None, names = ['review'], delimiter= '\\t')\n",
    "\n",
    "#Positve/Negative senntiment, which is stored as an array\n",
    "sentiment = train['sentiment']\n",
    "sentiment = np.asarray(sentiment)\n",
    "\n",
    "#Converted Pandas series format to list containing the Training reviews\n",
    "train_set = []\n",
    "for index, row in train.iterrows():\n",
    "    review  = str(train[\"review\"][index])\n",
    "    train_set.append(review)\n",
    "\n",
    "#Converted Pandas series format to list containing the test reviews\n",
    "test_set = []\n",
    "for index, row in test.iterrows():\n",
    "    review = str(train[\"review\"][index])\n",
    "    test_set.append(review)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18506, 3000)\n"
     ]
    }
   ],
   "source": [
    "#Extract Features into a sparse matrix from training data using vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer( analyzer = 'word',\n",
    "                                    stop_words='english',\n",
    "                                    max_features = 3000\n",
    "                                  )\n",
    "tfidf_train = tfidf_vectorizer.fit_transform(train_set)\n",
    "print tfidf_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18506, 3000)\n"
     ]
    }
   ],
   "source": [
    "tfidf_test = tfidf_vectorizer.transform(test_set)\n",
    "print tfidf_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#make sentiment predictions over entire test set\n",
    "predictions = []\n",
    "\n",
    "for documents in range(0,18506):\n",
    "    indicies = getResponse(tfidf_test[documents], tfidf_train, 19)\n",
    "    predictions.append(majority_vote(indicies, sentiment))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = open('predictions.dat', 'w')\n",
    "f.write(\"\\n\".join(map(lambda x: str(x), predictions)))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
